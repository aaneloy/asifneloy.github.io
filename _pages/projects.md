---
layout: archive
title: ""
permalink: /projects/
author_profile: true
---

{% include base_path %}

Current Projects <i class="fa fa-user-plus" aria-hidden="true"></i>
======

* <span style="font-size:larger;">**Feature Extraction and Prediction of Combined Text
and Survey Data using Two-Staged Modeling** || **Asif Ahmed Neloy** & <a href="https://www.maxturgeon.ca/" target="_blank">Dr. Maxime Turgeon</a> || August 2021 - Present</span> 
    * <a href="https://vada.cs.umanitoba.ca/profiles/asif-neloy/" target="_blank">Poster</a>
    * **Accepted** to be published on SENTIRE Workshop, <a href="https://icdm22.cse.usf.edu/index.html" target="_blank">22th IEEE International Conference on Data Mining (ICDM)</a>
    * Classification and text representation are important  tasks in many Natural Language Processing (NLP) applications.
Traditional NLP problems classify text, represent summarized
dictionaries, and segment larger textual context. However, due
to a lack of a modeling approach, their ability to extract
features is limited. Moreover, the use of these methods on smaller
datasets is unexplored and underdeveloped compared to more
popular research areas. In this work, we introduce a two-stage
modeling approach to combine classical statistical analysis with
NLP problems in a real-world dataset. With 96.69% training
and 70.56% testing accuracy, our proposed Convolutional neural
network (CNN) and Bidirectional Recurrent Neural Networks
(Bi-RNN) show exceptional performance in small dataset training
settings compared to complex state-of-the-art models. Moreover,
the experimental results from state-one modeling with a stacked
ensemble classifier and hypothesis testing support our novel
approach to combining the modeling approach.
 
<div style="text-align: center"> 
<a href="default.asp"><img src="/files/1.1.png" alt="bi-rnn" style="width:200px;height:150px;"> <img src="/files/1.2.png" alt="cnn" style="width:300px;height:200px;"> </a>

<a href="default.asp"><img src="/files/1.3.png" alt="odd_ratio1" style="width:300px;height:200px;"> <img src="/files/1.4.png" alt="odd_ratio2" style="width:300px;height:200px;"> </a>
</div>

* <span style="font-size:larger;">**Disentangled Conditional Variational Autoencoder for Unsupervised Anomaly Detection** || **Asif Ahmed Neloy** & <a href="https://www.maxturgeon.ca/" target="_blank">Dr. Maxime Turgeon</a> || January 2022 - Present</span> 
    * <a href="https://github.com/UMDimReduction/Disentangled-Conditional-Variational-Autoencoder" target="_blank">GitHub</a>
    * **Under Review**, <a href="https://iclr.cc/Conferences/2023" target="_blank">The Eleventh International Conference on Learning Representations (ICLR)</a>
    * Recently, generative models have shown promising performance in anomaly de-
tection tasks. Specifically, autoencoders learn representations of high-dimensional
data, and their reconstruction ability can be used to assess whether a new in-
stance is likely to be anomalous. However, the primary challenge of unsuper-
vised anomaly detection (UAD) is in learning appropriate disentangled features
and avoiding information loss, while incorporating known sources of variation
to improve the reconstruction. In this paper, we propose a novel architecture of
generative autoencoder by combining the frameworks of β-VAE, conditional vari-
ational autoencoder (CVAE), and the principle of total correlation (TC). We show
that our architecture improves the disentanglement of latent features, optimizes
TC loss more efficiently, and improves the ability to detect anomalies in an unsu-
pervised manner with respect to high-dimensional instances, such as in imaging
datasets. Through both qualitative and quantitative experiments on several bench-
mark datasets, we demonstrate that our proposed method excels in terms of both
anomaly detection and capturing disentangled features. Our analysis underlines
the importance of learning disentangled features for UAD tasks.

<div style="text-align: center">
<a href="default.asp"><img src="/files/3.1.png" alt="reconstruction" style="width:360px;height:800px;"> <img src="/files/3.2.png" alt="reconstruction" style="width:550px;height:800px;"> </a>
</div>
      
* <span style="font-size:larger;">**A Comprehensive Study of Auto‑Encoders for Anomaly Detection:
Efficiency and Trade‑Off** || **Asif Ahmed Neloy** & <a href="https://www.maxturgeon.ca/" target="_blank">Dr. Maxime Turgeon</a> || January 2021 - Present</span> 
    * <a href="https://github.com/UMDimReduction/autoencoder-Efficiency_vs_Tradeoffs" target="_blank">GitHub</a>
    * **Under Review**, <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=69" target="_blank">IEEE Transactions on Knowledge and Data Engineering</a>
    * Unsupervised Anomaly detection (UAD) is a significantly diverse research area explored for different application domains.
Over the years, many anomaly detection techniques such as clustering, generative, or variational inference-based methods are
developed to solve certain deficiencies and reform state-of-the-art techniques. However, deep learning and generative models enabled
a critical direction to identify unique problems and yield advanced approaches in recent years. Auto-encoder (AE) is one of the most
powerful techniques that combines generative and probabilistic variational modeling with deep architecture. The fundamental idea in
auto-encoders (AEs) is to learn the distribution of data in such a way that consequential sample data can be generated. Data
generation and the concept of adopting generative modeling have led to enormous research and variations in the design of AEs in the
field of unsupervised representation learning. In this study, we reviewed 11 AE divided into three categories and conducted
experiments to differentiate their reconstruction ability, sample generation, latent space visualization, and the accuracy of classifying
anomalous data. While experimenting, we also carefully observed the scope of reproducibility with different training parameters.
Fashion-MNIST and MNIST datasets are used in the reproducibility process to generate results from similar model setups and
hyperparameters. Finally, through the results obtained over the experiments, we undertake to riddle out the efficiency and trade-offs
among AEs.

<div style="text-align: center">
<a href="default.asp"><img src="/files/2.1.png" alt="reconstruction" style="width:200px;height:200px;"> <img src="/files/2.2.jpg" alt="reconstruction" style="width:200px;height:200px;"> </a>

<a href="default.asp"><img src="/files/2.3.png" alt="latent" style="width:200px;height:200px;"> <img src="/files/2.4.png" alt="latent" style="width:200px;height:200px;"> </a>
</div>

<br>

Past Projects <i class="fa fa-user-plus" aria-hidden="true"></i>
======


* <span style="font-size:larger;">**Predicting hypertension using machine learning models** || **Asif Ahmed Neloy** & <a href="https://ubclxing.github.io/" target="_blank">Dr. Li Xing</a> || VADA program Internship || June 2022 - September 2022</span>

<div style="text-align: center">
<a href="default.asp"><img src="/files/4.1.png" alt="accuracy" style="width:250px;height:200px;"> <img src="/files/4.2.png" alt="AUC" style="width:250px;height:100px;"> </a>

<a href="default.asp"><img src="/files/4.3.png" alt="f1" style="width:250px;height:200px;"> <img src="/files/4.4.png" alt="metrics" style="width:250px;height:200px;"> </a>
</div>  